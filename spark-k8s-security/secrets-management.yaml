---
# =============================================================================
# Secret Management for Spark on Kubernetes
# =============================================================================
# Version: 1.0
# Purpose: Production-ready secret management with external integration
# Integrations: Kubernetes Secrets, AWS Secrets Manager, HashiCorp Vault
# =============================================================================

# -----------------------------------------------------------------------------
# Example 1: Native Kubernetes Secrets
# -----------------------------------------------------------------------------
# Use for non-sensitive configuration or development
# For production, use external secret management (Vault, AWS Secrets Manager)
# -----------------------------------------------------------------------------

# S3 Credentials Secret
apiVersion: v1
kind: Secret
metadata:
  name: spark-s3-credentials
  namespace: spark-system
  labels:
    app: spark
    component: credentials
    managed-by: platform-team
  annotations:
    description: "S3 access credentials for Spark data lake"
    rotation-policy: "90-days"
    owner: "data-engineering@company.com"
type: Opaque
stringData:
  # AWS credentials (base64 encoded in production)
  aws-access-key-id: "AKIAIOSFODNN7EXAMPLE"
  aws-secret-access-key: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
  aws-region: "us-east-1"

  # S3 configuration
  s3-endpoint: "s3.amazonaws.com"
  s3-bucket: "spark-data-lake-prod"

---
# Database Credentials Secret
apiVersion: v1
kind: Secret
metadata:
  name: spark-database-credentials
  namespace: spark-system
  labels:
    app: spark
    component: credentials
type: Opaque
stringData:
  jdbc-url: "jdbc:postgresql://postgres.example.com:5432/analytics"
  jdbc-username: "spark_user"
  jdbc-password: "SuperSecurePassword123!"
  jdbc-driver: "org.postgresql.Driver"

---
# Kafka Credentials Secret
apiVersion: v1
kind: Secret
metadata:
  name: spark-kafka-credentials
  namespace: spark-system
  labels:
    app: spark
    component: credentials
type: Opaque
stringData:
  bootstrap-servers: "kafka-1.example.com:9093,kafka-2.example.com:9093"
  security-protocol: "SASL_SSL"
  sasl-mechanism: "PLAIN"
  sasl-username: "spark-consumer"
  sasl-password: "KafkaSecurePassword456!"

  # SSL certificates (PEM format)
  ca-cert: |
    -----BEGIN CERTIFICATE-----
    MIIDXTCCAkWgAwIBAgIJAKL0UG+mRKuFMA0GCSqGSIb3DQEBCwUAMEUxCzAJBgNV
    ...
    -----END CERTIFICATE-----

---
# =============================================================================
# External Secrets Operator (ESO) - AWS Secrets Manager Integration
# =============================================================================
# Install ESO: https://external-secrets.io/
# Benefits: Centralized secret management, automatic rotation, audit trail
# -----------------------------------------------------------------------------

# SecretStore - AWS Secrets Manager backend
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: aws-secrets-manager
  namespace: spark-system
spec:
  provider:
    aws:
      service: SecretsManager
      region: us-east-1

      # Authentication via IRSA (IAM Roles for Service Accounts)
      auth:
        jwt:
          serviceAccountRef:
            name: spark-driver

---
# ExternalSecret - S3 Credentials from AWS Secrets Manager
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: spark-s3-external
  namespace: spark-system
  labels:
    app: spark
    component: external-secret
spec:
  refreshInterval: 1h  # Refresh every hour

  secretStoreRef:
    name: aws-secrets-manager
    kind: SecretStore

  target:
    name: spark-s3-credentials-external
    creationPolicy: Owner
    template:
      engineVersion: v2
      data:
        # Template for Spark configuration format
        aws-credentials: |
          spark.hadoop.fs.s3a.access.key={{ .awsAccessKeyId }}
          spark.hadoop.fs.s3a.secret.key={{ .awsSecretAccessKey }}
          spark.hadoop.fs.s3a.endpoint={{ .s3Endpoint }}

  data:
    - secretKey: awsAccessKeyId
      remoteRef:
        key: prod/spark/s3-credentials
        property: access_key_id

    - secretKey: awsSecretAccessKey
      remoteRef:
        key: prod/spark/s3-credentials
        property: secret_access_key

    - secretKey: s3Endpoint
      remoteRef:
        key: prod/spark/s3-credentials
        property: endpoint

---
# ExternalSecret - Database Credentials from AWS Secrets Manager
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: spark-db-external
  namespace: spark-system
spec:
  refreshInterval: 30m

  secretStoreRef:
    name: aws-secrets-manager
    kind: SecretStore

  target:
    name: spark-database-credentials-external
    creationPolicy: Owner

  data:
    - secretKey: jdbc-url
      remoteRef:
        key: prod/spark/postgres-credentials
        property: jdbc_url

    - secretKey: jdbc-username
      remoteRef:
        key: prod/spark/postgres-credentials
        property: username

    - secretKey: jdbc-password
      remoteRef:
        key: prod/spark/postgres-credentials
        property: password

---
# =============================================================================
# HashiCorp Vault Integration
# =============================================================================

# SecretStore - Vault backend
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: vault-backend
  namespace: spark-system
spec:
  provider:
    vault:
      server: "https://vault.example.com"
      path: "secret"
      version: "v2"

      # Kubernetes authentication
      auth:
        kubernetes:
          mountPath: "kubernetes"
          role: "spark-role"
          serviceAccountRef:
            name: spark-driver

---
# ExternalSecret - Kafka Credentials from Vault
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: spark-kafka-vault
  namespace: spark-system
spec:
  refreshInterval: 15m

  secretStoreRef:
    name: vault-backend
    kind: SecretStore

  target:
    name: spark-kafka-credentials-vault
    creationPolicy: Owner

  data:
    - secretKey: bootstrap-servers
      remoteRef:
        key: spark/kafka
        property: bootstrap_servers

    - secretKey: sasl-username
      remoteRef:
        key: spark/kafka
        property: username

    - secretKey: sasl-password
      remoteRef:
        key: spark/kafka
        property: password

    - secretKey: ca-cert
      remoteRef:
        key: spark/kafka/certs
        property: ca_certificate

---
# =============================================================================
# Sealed Secrets (Bitnami) - GitOps-friendly encrypted secrets
# =============================================================================
# Install: https://github.com/bitnami-labs/sealed-secrets
# Benefit: Store encrypted secrets in Git, decrypt in-cluster
# -----------------------------------------------------------------------------

# SealedSecret - S3 Credentials (encrypted)
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: spark-s3-sealed
  namespace: spark-system
spec:
  encryptedData:
    # These values are encrypted by kubeseal CLI
    # Actual values would be base64-encoded encrypted strings
    aws-access-key-id: AgBh8F7nJ... (encrypted)
    aws-secret-access-key: AgC9Km2Lp... (encrypted)

  template:
    metadata:
      name: spark-s3-credentials-sealed
      labels:
        app: spark
        component: credentials
    type: Opaque

---
# =============================================================================
# Secret Rotation Job
# =============================================================================
# CronJob to trigger secret rotation from external sources
# -----------------------------------------------------------------------------
apiVersion: batch/v1
kind: CronJob
metadata:
  name: spark-secret-rotation
  namespace: spark-system
spec:
  schedule: "0 2 * * 0"  # Every Sunday at 2 AM
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3

  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: secret-rotation
            component: maintenance
        spec:
          serviceAccountName: spark-driver
          restartPolicy: OnFailure

          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000

          containers:
            - name: rotate-secrets
              image: amazon/aws-cli:2.13.0
              command:
                - /bin/bash
                - -c
                - |
                  #!/bin/bash
                  set -euo pipefail

                  echo "Starting secret rotation process..."

                  # Rotate AWS Secrets Manager secrets
                  aws secretsmanager rotate-secret \
                    --secret-id prod/spark/s3-credentials \
                    --rotation-lambda-arn arn:aws:lambda:us-east-1:123456789012:function:RotateSecret

                  # Rotate database credentials
                  aws secretsmanager rotate-secret \
                    --secret-id prod/spark/postgres-credentials \
                    --rotation-lambda-arn arn:aws:lambda:us-east-1:123456789012:function:RotateSecret

                  echo "Secret rotation completed successfully"

              env:
                - name: AWS_REGION
                  value: us-east-1

              securityContext:
                runAsNonRoot: true
                runAsUser: 1000
                readOnlyRootFilesystem: true
                allowPrivilegeEscalation: false

---
# =============================================================================
# ConfigMap - Secret Management Best Practices Documentation
# =============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: secret-management-guide
  namespace: spark-system
data:
  best-practices.md: |
    # Secret Management Best Practices

    ## 1. Never store secrets in Git
    - Use external secret management (AWS Secrets Manager, Vault)
    - Use Sealed Secrets for GitOps workflows
    - Add .env, secrets.yaml to .gitignore

    ## 2. Implement secret rotation
    - Rotate credentials every 90 days minimum
    - Use automated rotation where possible
    - Update dependent applications after rotation

    ## 3. Principle of least privilege
    - Grant minimal RBAC permissions for secret access
    - Use resourceNames to restrict specific secrets
    - Separate secrets by environment and team

    ## 4. Audit and monitoring
    - Enable audit logging for secret access
    - Monitor secret access patterns
    - Alert on unauthorized access attempts

    ## 5. Encryption at rest
    - Enable encryption at rest for etcd
    - Use KMS (AWS KMS, GCP KMS) for envelope encryption
    - Verify encryption is enabled: kubectl get secret -o yaml

    ## 6. Secret injection patterns
    - Prefer environment variables over mounted files
    - Use init containers to fetch secrets before app start
    - Avoid logging secret values

    ## 7. Secret naming conventions
    - Use descriptive names: spark-{service}-credentials
    - Include environment: spark-s3-credentials-prod
    - Add metadata labels for tracking

    ## 8. Secret expiration
    - Set expiration dates in annotations
    - Implement automated alerts for expiring secrets
    - Test secret rotation procedures regularly

  rotation-checklist.md: |
    # Secret Rotation Checklist

    ## Pre-rotation
    - [ ] Identify all applications using the secret
    - [ ] Schedule maintenance window if needed
    - [ ] Backup current secret values
    - [ ] Prepare rollback procedure
    - [ ] Notify stakeholders

    ## During rotation
    - [ ] Generate new credentials in identity provider
    - [ ] Update secret in Kubernetes/Secrets Manager
    - [ ] Verify new credentials work in staging
    - [ ] Trigger application restart/reload
    - [ ] Monitor application logs for errors

    ## Post-rotation
    - [ ] Verify all applications using new credentials
    - [ ] Revoke old credentials after grace period
    - [ ] Update documentation
    - [ ] Record rotation in change log
    - [ ] Schedule next rotation

  emergency-procedures.md: |
    # Emergency Secret Leak Procedures

    ## 1. Immediate actions (< 5 minutes)
    - Revoke compromised credentials immediately
    - Rotate all related secrets
    - Alert security team
    - Enable additional monitoring

    ## 2. Investigation (< 1 hour)
    - Check audit logs for unauthorized access
    - Identify scope of leak (which secrets, when)
    - Review recent Git commits
    - Check application logs

    ## 3. Remediation (< 4 hours)
    - Deploy new credentials to all environments
    - Update all dependent applications
    - Verify no unauthorized access occurred
    - Document incident timeline

    ## 4. Post-incident (< 24 hours)
    - Conduct root cause analysis
    - Update security procedures
    - Train team on prevention
    - Implement additional safeguards
